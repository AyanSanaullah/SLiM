# Fluxo de Requests para Receber Respostas dos Modelos

## ğŸ”„ Diagrama do Fluxo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente       â”‚
â”‚   (VocÃª)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 1. POST /api/v1/agents
          â”‚    {"user_id": "user123", "training_data": "..."}
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask API     â”‚
â”‚   (app.py)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 2. Cria agent pipeline
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UserAgentManagerâ”‚
â”‚ (user_agent_    â”‚
â”‚  manager.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 3. Executa pipeline
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataProcessor   â”‚â”€â”€â”€â–¶â”‚ ModelTrainer    â”‚â”€â”€â”€â–¶â”‚ ModelEvaluator  â”‚
â”‚ Agent           â”‚    â”‚ Agent           â”‚    â”‚ Agent           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 4. Status: ready
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente       â”‚
â”‚   (VocÃª)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 5. POST /api/v1/agents/user123/inference
          â”‚    {"prompt": "Sua pergunta aqui"}
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask API     â”‚
â”‚   (app.py)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 6. make_inference()
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini API      â”‚
â”‚ (Modelo base)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ 7. Resposta personalizada
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente       â”‚
â”‚   (VocÃª)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Passo a Passo Detalhado

### Fase 1: CriaÃ§Ã£o do Agent
```
Cliente â†’ Flask API â†’ UserAgentManager â†’ Pipeline de Agents
```

1. **Cliente faz POST** para `/api/v1/agents`
2. **Flask API** recebe a requisiÃ§Ã£o
3. **UserAgentManager** cria o pipeline de agents
4. **Pipeline** Ã© executado em thread separada

### Fase 2: Treinamento (AutomÃ¡tico)
```
DataProcessor â†’ ModelTrainer â†’ ModelEvaluator â†’ ModelDeployer
```

1. **DataProcessor**: Processa os dados de treinamento
2. **ModelTrainer**: Treina o modelo personalizado
3. **ModelEvaluator**: Avalia a performance
4. **ModelDeployer**: Prepara para deploy

### Fase 3: InferÃªncia (Sua Pergunta)
```
Cliente â†’ Flask API â†’ Gemini API â†’ Resposta Personalizada
```

1. **Cliente faz POST** para `/api/v1/agents/{user_id}/inference`
2. **Flask API** valida a requisiÃ§Ã£o
3. **Gemini API** gera resposta usando contexto personalizado
4. **Cliente recebe** resposta personalizada

## ğŸ” Estados do Sistema

### Estados do Agent
```
initializing â†’ processing â†’ ready
     â†“             â†“          â†“
   Criando    Treinando   Pronto para
   pipeline   modelo      responder
```

### Estados de Erro
```
initializing â†’ error
processing â†’ error
```

## ğŸ“Š Exemplo de SequÃªncia de Requests

### Request 1: Criar Agent
```bash
POST /api/v1/agents
{
  "user_id": "python_expert",
  "training_data": "Sou especialista em Python..."
}

Response:
{
  "message": "Agent pipeline created...",
  "status": "created"
}
```

### Request 2: Verificar Status
```bash
GET /api/v1/agents/python_expert/status

Response:
{
  "status": "processing"  // ou "ready" ou "error"
}
```

### Request 3: Fazer Pergunta (quando ready)
```bash
POST /api/v1/agents/python_expert/inference
{
  "prompt": "Como criar uma API Flask?"
}

Response:
{
  "response": "Para criar uma API Flask...",
  "timestamp": "2024-01-15T10:40:00Z"
}
```

## â±ï¸ Timeline TÃ­pica

```
T+0s:   Cliente cria agent
T+5s:   Status: initializing
T+10s:  Status: processing
T+30s:  Status: ready
T+35s:  Cliente faz primeira pergunta
T+36s:  Cliente recebe resposta
```

## ğŸ”§ Componentes Envolvidos

### 1. Flask API (app.py)
- Recebe requests HTTP
- Valida dados
- Chama UserAgentManager
- Retorna respostas JSON

### 2. UserAgentManager
- Gerencia agents por usuÃ¡rio
- Cria pipelines de treinamento
- Controla estados
- Faz inferÃªncia

### 3. Pipeline de Agents
- **DataProcessorAgent**: Processa dados
- **ModelTrainerAgent**: Treina modelo
- **ModelEvaluatorAgent**: Avalia performance
- **ModelDeployerAgent**: Deploy

### 4. Gemini API
- Modelo base para inferÃªncia
- Usa contexto personalizado
- Gera respostas

## ğŸ¯ Pontos Chave

1. **Um Request para Criar**: POST `/api/v1/agents`
2. **MÃºltiplos Requests para Status**: GET `/api/v1/agents/{user_id}/status`
3. **MÃºltiplos Requests para Perguntas**: POST `/api/v1/agents/{user_id}/inference`
4. **Aguardar Status "ready"** antes de fazer perguntas
5. **Contexto Personalizado** Ã© usado em cada resposta

## ğŸš¨ Fluxo de Erro

```
Request â†’ ValidaÃ§Ã£o â†’ Erro â†’ Response com error
```

Exemplos de erros:
- Agent nÃ£o encontrado
- Modelo nÃ£o estÃ¡ pronto
- Dados invÃ¡lidos
- Erro de conexÃ£o

## ğŸ“ˆ Monitoramento

### Endpoints de Monitoramento
- `GET /health`: Status do serviÃ§o
- `GET /api/v1/agents`: Lista todos os agents
- `GET /api/v1/config`: ConfiguraÃ§Ã£o atual

### Logs Importantes
- CriaÃ§Ã£o de agents
- Status de treinamento
- Requests de inferÃªncia
- Erros e exceÃ§Ãµes

---

**Resumo**: O fluxo Ã© simples: criar agent â†’ aguardar ready â†’ fazer perguntas. Cada pergunta gera uma resposta personalizada baseada nos dados de treinamento do usuÃ¡rio.
